{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation of UCDD on SEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEA dataset locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "abrupt_sea_path = '../Datasets_concept_drift/synthetic_data/abrupt_drift/sea_1_abrupt_drift_0_noise_balanced.arff'\n",
    "gradual_sea_paths = [\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_05.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_1.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_5.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_10.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_20.arff'\n",
    "]\n",
    "all_sea_data_paths = [abrupt_sea_path] + gradual_sea_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accept and preprocess SEA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  4.636430  6.639370  0.066740  b'groupB'\n",
      "99996  4.251993  3.351235  5.652197  b'groupA'\n",
      "99997  4.131405  6.371722  3.125554  b'groupB'\n",
      "99998  1.404214  4.392506  9.298558  b'groupA'\n",
      "99999  7.231749  8.770465  3.925490  b'groupB'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  2.074508  1.775662  1.318589  b'groupA'\n",
      "99996  4.636430  6.639370  0.066740  b'groupB'\n",
      "99997  4.251993  3.351235  5.652197  b'groupA'\n",
      "99998  4.131405  6.371722  3.125554  b'groupB'\n",
      "99999  1.404214  4.392506  9.298558  b'groupA'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  2.261206  1.404770  3.977088  b'groupA'\n",
      "99996  0.795885  8.915077  6.892585  b'groupB'\n",
      "99997  0.353597  1.289198  0.001943  b'groupA'\n",
      "99998  6.540503  5.698432  7.743243  b'groupB'\n",
      "99999  2.074508  1.775662  1.318589  b'groupA'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  7.680433  9.606008  5.626119  b'groupB'\n",
      "99996  1.336234  3.864737  1.698313  b'groupA'\n",
      "99997  0.541297  9.975611  6.822081  b'groupB'\n",
      "99998  1.709441  4.517255  8.083470  b'groupA'\n",
      "99999  0.778983  9.326919  2.996122  b'groupA'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  8.630346  3.981509  1.040496  b'groupB'\n",
      "99996  0.656783  5.144250  9.648631  b'groupA'\n",
      "99997  8.299312  7.466245  5.592216  b'groupB'\n",
      "99998  2.728767  5.140916  0.727831  b'groupA'\n",
      "99999  8.852912  3.855575  6.128628  b'groupB'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  8.479838  4.037801  7.474048  b'groupB'\n",
      "99996  0.587347  2.725972  8.395393  b'groupA'\n",
      "99997  1.297264  9.227339  6.843533  b'groupB'\n",
      "99998  2.009023  5.305785  1.423271  b'groupA'\n",
      "99999  9.680480  4.642564  3.628668  b'groupB'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import accepting\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sea_reference_batches = {}\n",
    "sea_testing_batches = {}\n",
    "for sea_path in all_sea_data_paths:\n",
    "    df_x, df_y = accepting.get_clean_df(sea_path)\n",
    "    df_y = pd.DataFrame(LabelEncoder().fit_transform(df_y))\n",
    "\n",
    "    df_x_ref, df_x_test, df_y_ref, df_y_test = sklearn.model_selection.train_test_split(\n",
    "        df_x, df_y, test_size=0.7, shuffle=False)\n",
    "    \n",
    "    reference_data = df_x_ref.to_numpy()\n",
    "    testing_data = df_x_test.to_numpy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(reference_data)\n",
    "    reference_data = scaler.transform(reference_data)\n",
    "    testing_data = scaler.transform(testing_data)\n",
    "    \n",
    "    num_ref_batches = 3\n",
    "    num_test_batches = 7\n",
    "    ref_batches = np.array_split(reference_data, num_ref_batches)\n",
    "    test_batches = np.array_split(testing_data, num_test_batches)\n",
    "    \n",
    "    sea_reference_batches[sea_path] = ref_batches\n",
    "    sea_testing_batches[sea_path] = test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best tol and max_iter in SEA (the drift type is irrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmeans_verbose_helpers\n",
    "\n",
    "\n",
    "def write_kmeans_results_ucdd_helper(output_filename_no_extension, ref_batches, n_init, max_iter, tol, random_state):\n",
    "    # dummy = [np.asarray(1), np.asarray(2), np.asarray(3)]\n",
    "    combinations = []\n",
    "    for i in range(3):\n",
    "    #     combinations.append(np.vstack((dummy[i], dummy[(i + 1) % 3])))\n",
    "        combinations.append(np.vstack((ref_batches[i], ref_batches[(i + 1) % 3])))\n",
    "        \n",
    "    all_results_from_combinations = []\n",
    "    for i, combination in enumerate(combinations):\n",
    "        filename = output_filename_no_extension + str(i) + '.txt'\n",
    "        print('filename', filename)\n",
    "        kmeans_verbose_helpers.write_verbose_kmeans_to_file(result_filename=output_filename_no_extension + str(i) + '.txt',\n",
    "                                     data_to_cluster=combination,\n",
    "                                     n_clusters=2, n_init=n_init, max_iter=max_iter, tol=tol, random_state=random_state)\n",
    "        output_dicts = kmeans_verbose_helpers.convert_kmeans_output_file_to_dicts(filename, n_init=n_init)\n",
    "        all_results_from_combinations.append(output_dicts)\n",
    "        kmeans_verbose_helpers.print_stats_from_kmeans_output_dicts(output_dicts)\n",
    "        \n",
    "    kmeans_verbose_helpers.print_stats_from_all_combinations(all_results_from_combinations)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename sea_new_output0.txt\n",
      "random state: 1053\n",
      "total number of results: 100\n",
      "maximum number of iterations: 77\n",
      "minimum initial inertia: 3807.187051337405\n",
      "maximum initial inertia: 8731.074732381052\n",
      "number of unique final inertia values: 19\n",
      "minimum final inertia: 3554.5339834841066\n",
      "maximum final inertia: 3652.0641391502845\n",
      "total number of convergences: 100\n",
      "number of strict convergences: 100\n",
      "number of tol-based convergences: 0\n",
      "filename sea_new_output1.txt\n",
      "random state: 1053\n",
      "total number of results: 100\n",
      "maximum number of iterations: 54\n",
      "minimum initial inertia: 3963.912240518916\n",
      "maximum initial inertia: 8146.817583220964\n",
      "number of unique final inertia values: 5\n",
      "minimum final inertia: 3522.635321428201\n",
      "maximum final inertia: 3632.905333372652\n",
      "total number of convergences: 100\n",
      "number of strict convergences: 100\n",
      "number of tol-based convergences: 0\n",
      "filename sea_new_output2.txt\n",
      "random state: 1053\n",
      "total number of results: 100\n",
      "maximum number of iterations: 71\n",
      "minimum initial inertia: 3887.476245307372\n",
      "maximum initial inertia: 8426.6262988874\n",
      "number of unique final inertia values: 13\n",
      "minimum final inertia: 3555.233746395852\n",
      "maximum final inertia: 3613.5161478893065\n",
      "total number of convergences: 100\n",
      "number of strict convergences: 100\n",
      "number of tol-based convergences: 0\n",
      "{'total_max_iterations': 77, 'total_min_init_inertia': 3807.187051337405, 'total_max_init_inertia': 8731.074732381052, 'total_min_final_inertia': 3522.635321428201, 'total_max_final_inertia': 3652.0641391502845, 'total_num_convergences': 300, 'total_num_strict_convergences': 300, 'total_num_tol_based_convergences': 0}\n"
     ]
    }
   ],
   "source": [
    "write_kmeans_results_ucdd_helper('sea_new_output', sea_reference_batches[abrupt_sea_path], n_init=100, max_iter=500, tol=0,\n",
    "                                 random_state=1053)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use them for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state\n",
      "0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "random_state\n",
      "100\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.08838834764831843\n",
      "random_state\n",
      "200\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.06804138174397717\n",
      "random_state\n",
      "300\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.0625\n",
      "random_state\n",
      "400\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.05477225575051661\n",
      "random_state\n",
      "500\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.048112522432468816\n",
      "final fpr mean 0.0\n",
      "final latency mean 0.16666666666666666\n",
      "random_state\n",
      "0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "random_state\n",
      "100\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.0\n",
      "final fpr mean 0.0\n",
      "final latency mean 0.25\n",
      "random_state\n",
      "0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "random_state\n",
      "100\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.0\n",
      "final fpr mean 0.0\n",
      "final latency mean 0.25\n",
      "random_state\n",
      "0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "random_state\n",
      "100\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.0\n",
      "final fpr mean 0.0\n",
      "final latency mean 0.0\n",
      "random_state\n",
      "0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "random_state\n",
      "100\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.0\n",
      "final fpr mean 0.0\n",
      "final latency mean 0.25\n",
      "random_state\n",
      "0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "random_state\n",
      "100\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "n_init 100 max_iter 77000 tol 0\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.0\n",
      "final fpr mean 0.0\n",
      "final latency mean 0.75\n",
      "SEA STATS\n",
      "{'../Datasets_concept_drift/synthetic_data/abrupt_drift/sea_1_abrupt_drift_0_noise_balanced.arff': {'runs_results_bool': [[False, False, True, True, True, True, True], [False, False, False, True, True, True, True], [False, False, False, True, True, True, True], [False, False, True, True, True, True, True], [False, False, False, True, True, True, True], [False, False, False, True, True, True, True]], 'final_fpr_mean': 0.0, 'fpr_std_err': 0.0, 'final_latency_mean': 0.16666666666666666, 'latency_std_err': 0.048112522432468816}, '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_05.arff': {'runs_results_bool': [[False, False, False, True, True, True, True], [False, False, False, True, True, True, True]], 'final_fpr_mean': 0.0, 'fpr_std_err': 0.0, 'final_latency_mean': 0.25, 'latency_std_err': 0.0}, '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_1.arff': {'runs_results_bool': [[False, False, False, True, True, True, True], [False, False, False, True, True, True, True]], 'final_fpr_mean': 0.0, 'fpr_std_err': 0.0, 'final_latency_mean': 0.25, 'latency_std_err': 0.0}, '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_5.arff': {'runs_results_bool': [[False, False, True, True, True, True, True], [False, False, True, True, True, True, True]], 'final_fpr_mean': 0.0, 'fpr_std_err': 0.0, 'final_latency_mean': 0.0, 'latency_std_err': 0.0}, '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_10.arff': {'runs_results_bool': [[False, False, False, True, True, True, True], [False, False, False, True, True, True, True]], 'final_fpr_mean': 0.0, 'fpr_std_err': 0.0, 'final_latency_mean': 0.25, 'latency_std_err': 0.0}, '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_20.arff': {'runs_results_bool': [[False, False, False, False, False, True, True], [False, False, False, False, False, True, True]], 'final_fpr_mean': 0.0, 'fpr_std_err': 0.0, 'final_latency_mean': 0.75, 'latency_std_err': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "import ucdd_eval\n",
    "import ucdd_supported_parameters as spms\n",
    "\n",
    "\n",
    "\n",
    "sea_stats = {}\n",
    "for sea_path in all_sea_data_paths:\n",
    "    runs_results_bool, final_fpr_mean, fpr_std_err, final_latency_mean, latency_std_err = \\\n",
    "        ucdd_eval.all_drifting_batches_randomness_robust(\n",
    "        sea_reference_batches[sea_path],\n",
    "        sea_testing_batches[sea_path],\n",
    "        train_batch_strategy=spms.TrainBatchStrategies.MAJORITY,\n",
    "        additional_check=True,\n",
    "        n_init=100,\n",
    "        max_iter=77000,\n",
    "        tol=0,\n",
    "        true_drift_idx=2,\n",
    "        min_runs=2\n",
    "    )\n",
    "    sea_stats[sea_path] = {\n",
    "        'runs_results_bool': runs_results_bool,\n",
    "        'final_fpr_mean': final_fpr_mean,\n",
    "        'fpr_std_err': fpr_std_err,\n",
    "        'final_latency_mean': final_latency_mean,\n",
    "        'latency_std_err': latency_std_err\n",
    "    }\n",
    "\n",
    "print('SEA STATS')\n",
    "print(sea_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "\n",
    "\n",
    "final_result_dict = {\n",
    "    'type_of_data': [], 'dataset': [], 'drift': [], 'width': [], 'encoding': [],\n",
    "    'train_batch_strategy': [], 'additional_check': [],\n",
    "    'n_init': [], 'max_iter': [], 'tol': [],\n",
    "    'FPR_mean': [], 'latency_mean': []\n",
    "}\n",
    "\n",
    "for data_path, stats_dict in sea_stats.items():\n",
    "    synthetic_filename_info = helpers.synthetic_data_information(data_path)\n",
    "    encoding = 'exclude'\n",
    "    fpr_mean = float(stats_dict['final_fpr_mean'])\n",
    "    latency_mean = float(stats_dict['final_latency_mean'])\n",
    "    \n",
    "    final_result_dict['type_of_data'].append(synthetic_filename_info['type_of_data'])\n",
    "    final_result_dict['dataset'].append(synthetic_filename_info['dataset_name'])\n",
    "    final_result_dict['drift'].append(synthetic_filename_info['drift_type'])\n",
    "    final_result_dict['width'].append(synthetic_filename_info['drift_width'])\n",
    "    final_result_dict['encoding'].append(encoding)\n",
    "    final_result_dict['train_batch_strategy'].append('majority')\n",
    "    final_result_dict['additional_check'].append('true')\n",
    "    final_result_dict['n_init'].append(100)\n",
    "    final_result_dict['max_iter'].append(77000)\n",
    "    final_result_dict['tol'].append(0)\n",
    "    final_result_dict['FPR_mean'].append(fpr_mean)\n",
    "    final_result_dict['latency_mean'].append(latency_mean)\n",
    "    \n",
    "final_result_df = pd.DataFrame.from_dict(final_result_dict)\n",
    "sorted_final_result_df = final_result_df.sort_values(['drift', 'dataset', 'encoding', 'width'])\n",
    "final_result_df.to_csv('sea_jupyter_results_majority.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
