{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation of MSSW on SEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEA dataset locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abrupt_sea_path = '../Datasets_concept_drift/synthetic_data/abrupt_drift/sea_1_abrupt_drift_0_noise_balanced.arff'\n",
    "gradual_sea_paths = [\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_05.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_1.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_5.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_10.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_20.arff'\n",
    "]\n",
    "all_sea_data_paths = [abrupt_sea_path] + gradual_sea_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accept and preprocess SEA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  4.636430  6.639370  0.066740  b'groupB'\n",
      "99996  4.251993  3.351235  5.652197  b'groupA'\n",
      "99997  4.131405  6.371722  3.125554  b'groupB'\n",
      "99998  1.404214  4.392506  9.298558  b'groupA'\n",
      "99999  7.231749  8.770465  3.925490  b'groupB'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\eval_helpers\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  2.074508  1.775662  1.318589  b'groupA'\n",
      "99996  4.636430  6.639370  0.066740  b'groupB'\n",
      "99997  4.251993  3.351235  5.652197  b'groupA'\n",
      "99998  4.131405  6.371722  3.125554  b'groupB'\n",
      "99999  1.404214  4.392506  9.298558  b'groupA'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\eval_helpers\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  2.261206  1.404770  3.977088  b'groupA'\n",
      "99996  0.795885  8.915077  6.892585  b'groupB'\n",
      "99997  0.353597  1.289198  0.001943  b'groupA'\n",
      "99998  6.540503  5.698432  7.743243  b'groupB'\n",
      "99999  2.074508  1.775662  1.318589  b'groupA'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\eval_helpers\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  7.680433  9.606008  5.626119  b'groupB'\n",
      "99996  1.336234  3.864737  1.698313  b'groupA'\n",
      "99997  0.541297  9.975611  6.822081  b'groupB'\n",
      "99998  1.709441  4.517255  8.083470  b'groupA'\n",
      "99999  0.778983  9.326919  2.996122  b'groupA'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\eval_helpers\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  8.630346  3.981509  1.040496  b'groupB'\n",
      "99996  0.656783  5.144250  9.648631  b'groupA'\n",
      "99997  8.299312  7.466245  5.592216  b'groupB'\n",
      "99998  2.728767  5.140916  0.727831  b'groupA'\n",
      "99999  8.852912  3.855575  6.128628  b'groupB'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\eval_helpers\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  8.479838  4.037801  7.474048  b'groupB'\n",
      "99996  0.587347  2.725972  8.395393  b'groupA'\n",
      "99997  1.297264  9.227339  6.843533  b'groupB'\n",
      "99998  2.009023  5.305785  1.423271  b'groupA'\n",
      "99999  9.680480  4.642564  3.628668  b'groupB'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\eval_helpers\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from eval_helpers import accepting\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sea_reference_batches = {}\n",
    "sea_testing_batches = {}\n",
    "for sea_path in all_sea_data_paths:\n",
    "    df_x, df_y = accepting.get_clean_df(sea_path)\n",
    "    df_y = pd.DataFrame(LabelEncoder().fit_transform(df_y))\n",
    "\n",
    "    df_x_ref, df_x_test, df_y_ref, df_y_test = sklearn.model_selection.train_test_split(\n",
    "        df_x, df_y, test_size=0.7, shuffle=False)\n",
    "    \n",
    "    reference_data = df_x_ref.to_numpy()\n",
    "    testing_data = df_x_test.to_numpy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(reference_data)\n",
    "    reference_data = scaler.transform(reference_data)\n",
    "    testing_data = scaler.transform(testing_data)\n",
    "    \n",
    "    num_ref_batches = 3\n",
    "    num_test_batches = 7\n",
    "    ref_batches = np.array_split(reference_data, num_ref_batches)\n",
    "    test_batches = np.array_split(testing_data, num_test_batches)\n",
    "    \n",
    "    \n",
    "    sea_reference_batches[sea_path] = ref_batches\n",
    "    sea_testing_batches[sea_path] = test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best tol and max_iter in SEA (the drift type is irrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something\n"
     ]
    }
   ],
   "source": [
    "from eval_helpers import kmeans_verbose_helpers\n",
    "\n",
    "\n",
    "def write_kmeans_results_ucdd_helper(output_filename_no_extension, ref_batches, n_init, max_iter, tol, random_state):\n",
    "    # dummy = [np.asarray(1), np.asarray(2), np.asarray(3)]\n",
    "    combinations = []\n",
    "    for i in range(3):\n",
    "    #     combinations.append(np.vstack((dummy[i], dummy[(i + 1) % 3])))\n",
    "        combinations.append(np.vstack((ref_batches[i], ref_batches[(i + 1) % 3])))\n",
    "        \n",
    "    all_results_from_combinations = []\n",
    "    for i, combination in enumerate(combinations):\n",
    "        filename = output_filename_no_extension + str(i) + '.txt'\n",
    "        print('filename', filename)\n",
    "        kmeans_verbose_helpers.write_verbose_kmeans_to_file(result_filename=output_filename_no_extension + str(i) + '.txt',\n",
    "                                     data_to_cluster=combination,\n",
    "                                     n_clusters=2, n_init=n_init, max_iter=max_iter, tol=tol, random_state=random_state)\n",
    "        output_dicts = kmeans_verbose_helpers.convert_kmeans_output_file_to_dicts(filename, n_init=n_init)\n",
    "        all_results_from_combinations.append(output_dicts)\n",
    "        kmeans_verbose_helpers.print_stats_from_kmeans_output_dicts(output_dicts)\n",
    "        \n",
    "    kmeans_verbose_helpers.print_stats_from_all_combinations(all_results_from_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename sea_output0.txt\n",
      "random state: 1053\n",
      "total number of results: 100\n",
      "maximum number of iterations: 77\n",
      "minimum initial inertia: 3807.187051337405\n",
      "maximum initial inertia: 8731.074732381052\n",
      "number of unique final inertia values: 18\n",
      "minimum final inertia: 3554.5339834841066\n",
      "maximum final inertia: 3652.0641391502845\n",
      "total number of convergences: 100\n",
      "number of strict convergences: 100\n",
      "number of tol-based convergences: 0\n",
      "filename sea_output1.txt\n",
      "random state: 1053\n",
      "total number of results: 100\n",
      "maximum number of iterations: 54\n",
      "minimum initial inertia: 3963.912240518916\n",
      "maximum initial inertia: 8146.817583220964\n",
      "number of unique final inertia values: 5\n",
      "minimum final inertia: 3522.635321428201\n",
      "maximum final inertia: 3632.905333372651\n",
      "total number of convergences: 100\n",
      "number of strict convergences: 100\n",
      "number of tol-based convergences: 0\n",
      "filename sea_output2.txt\n",
      "random state: 1053\n",
      "total number of results: 100\n",
      "maximum number of iterations: 71\n",
      "minimum initial inertia: 3887.476245307372\n",
      "maximum initial inertia: 8426.6262988874\n",
      "number of unique final inertia values: 13\n",
      "minimum final inertia: 3555.233746395852\n",
      "maximum final inertia: 3613.5161478893065\n",
      "total number of convergences: 100\n",
      "number of strict convergences: 100\n",
      "number of tol-based convergences: 0\n",
      "{'total_max_iterations': 77, 'total_min_init_inertia': 3807.187051337405, 'total_max_init_inertia': 8731.074732381052, 'total_min_final_inertia': 3522.635321428201, 'total_max_final_inertia': 3652.0641391502845, 'total_num_convergences': 300, 'total_num_strict_convergences': 300, 'total_num_tol_based_convergences': 0}\n"
     ]
    }
   ],
   "source": [
    "write_kmeans_results_ucdd_helper('sea_output', sea_reference_batches[abrupt_sea_path], n_init=100, max_iter=500, tol=0,\n",
    "                                 random_state=1053)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use them for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state\n",
      "0\n",
      "#### TEST BATCH 0 of 7 ####\n",
      "#### TEST BATCH 1 of 7 ####\n",
      "#### TEST BATCH 2 of 7 ####\n",
      "#### TEST BATCH 3 of 7 ####\n",
      "#### TEST BATCH 4 of 7 ####\n",
      "#### TEST BATCH 5 of 7 ####\n",
      "#### TEST BATCH 6 of 7 ####\n",
      "random_state\n",
      "100\n",
      "#### TEST BATCH 0 of 7 ####\n",
      "#### TEST BATCH 1 of 7 ####\n",
      "#### TEST BATCH 2 of 7 ####\n",
      "#### TEST BATCH 3 of 7 ####\n",
      "#### TEST BATCH 4 of 7 ####\n",
      "#### TEST BATCH 5 of 7 ####\n",
      "#### TEST BATCH 6 of 7 ####\n",
      "fpr s.e. 0.0\n",
      "latency s.e. 0.0\n",
      "final fpr mean 0.5\n",
      "final latency mean 0.0\n",
      "random_state\n",
      "0\n",
      "#### TEST BATCH 0 of 7 ####\n",
      "#### TEST BATCH 1 of 7 ####\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<__array_function__ internals>:177\u001B[0m, in \u001B[0;36mwhere\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'sklearn.cluster._k_means_common._relocate_empty_clusters_dense'\n",
      "Traceback (most recent call last):\n",
      "  File \"<__array_function__ internals>\", line 177, in where\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<__array_function__ internals>:177\u001B[0m, in \u001B[0;36mwhere\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'sklearn.cluster._k_means_common._relocate_empty_clusters_dense'\n",
      "Traceback (most recent call last):\n",
      "  File \"<__array_function__ internals>\", line 177, in where\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<__array_function__ internals>:177\u001B[0m, in \u001B[0;36mwhere\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'sklearn.cluster._k_means_common._relocate_empty_clusters_dense'\n",
      "Traceback (most recent call last):\n",
      "  File \"<__array_function__ internals>\", line 177, in where\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TEST BATCH 2 of 7 ####\n",
      "#### TEST BATCH 3 of 7 ####\n",
      "#### TEST BATCH 4 of 7 ####\n",
      "#### TEST BATCH 5 of 7 ####\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<__array_function__ internals>:177\u001B[0m, in \u001B[0;36mwhere\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'sklearn.cluster._k_means_common._relocate_empty_clusters_dense'\n",
      "Traceback (most recent call last):\n",
      "  File \"<__array_function__ internals>\", line 177, in where\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TEST BATCH 6 of 7 ####\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<__array_function__ internals>:177\u001B[0m, in \u001B[0;36mwhere\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'sklearn.cluster._k_means_common._relocate_empty_clusters_dense'\n",
      "Traceback (most recent call last):\n",
      "  File \"<__array_function__ internals>\", line 177, in where\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m sea_stats \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sea_path \u001B[38;5;129;01min\u001B[39;00m all_sea_data_paths:\n\u001B[0;32m      6\u001B[0m     runs_results_bool, final_fpr_mean, fpr_std_err, final_latency_mean, latency_std_err \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m----> 7\u001B[0m         \u001B[43mucdd_eval\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mall_drifting_batches_randomness_robust\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43msea_reference_batches\u001B[49m\u001B[43m[\u001B[49m\u001B[43msea_path\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43msea_testing_batches\u001B[49m\u001B[43m[\u001B[49m\u001B[43msea_path\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_ref_batches_drift\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43madditional_check\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m77000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrue_drift_idx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_runs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     sea_stats[sea_path] \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     19\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mruns_results_bool\u001B[39m\u001B[38;5;124m'\u001B[39m: runs_results_bool,\n\u001B[0;32m     20\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfinal_fpr_mean\u001B[39m\u001B[38;5;124m'\u001B[39m: final_fpr_mean,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatency_std_err\u001B[39m\u001B[38;5;124m'\u001B[39m: latency_std_err\n\u001B[0;32m     24\u001B[0m     }\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSEA STATS\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\core\\ucdd_eval.py:57\u001B[0m, in \u001B[0;36mall_drifting_batches_randomness_robust\u001B[1;34m(reference_data_batches, testing_data_batches, min_ref_batches_drift, additional_check, n_init, max_iter, tol, true_drift_idx, first_random_state, min_runs, std_err_threshold)\u001B[0m\n\u001B[0;32m     55\u001B[0m random_state \u001B[38;5;241m=\u001B[39m first_random_state\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m num_runs \u001B[38;5;241m<\u001B[39m min_runs \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(fpr_std_err, latency_std_err) \u001B[38;5;241m>\u001B[39m std_err_threshold:\n\u001B[1;32m---> 57\u001B[0m     drifting_batches_bool \u001B[38;5;241m=\u001B[39m \u001B[43mucdd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mall_drifting_batches\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreference_data_batches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtesting_data_batches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_ref_batches_drift\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmin_ref_batches_drift\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m        \u001B[49m\u001B[43madditional_check\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madditional_check\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;66;03m# print('drifting_batches_bool')\u001B[39;00m\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# print(drifting_batches_bool)\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     drift_locations \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;28mlen\u001B[39m(drifting_batches_bool))[drifting_batches_bool]\n",
      "File \u001B[1;32m~\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\core\\ucdd.py:194\u001B[0m, in \u001B[0;36mall_drifting_batches\u001B[1;34m(reference_data_batches, testing_data_batches, min_ref_batches_drift, additional_check, n_init, max_iter, tol, random_state)\u001B[0m\n\u001B[0;32m    192\u001B[0m num_ref_drifts \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;66;03m# how many training batches signal drift against this testing batch\u001B[39;00m\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j, ref_window \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(reference_data_batches):\n\u001B[1;32m--> 194\u001B[0m     drift_here \u001B[38;5;241m=\u001B[39m \u001B[43mconcept_drift_detected\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m        \u001B[49m\u001B[43mref_window\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_window\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madditional_check\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_init\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drift_here:\n\u001B[0;32m    197\u001B[0m         num_ref_drifts \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\core\\ucdd.py:143\u001B[0m, in \u001B[0;36mconcept_drift_detected\u001B[1;34m(ref_window, test_window, additional_check, n_init, max_iter, tol, random_state, threshold, debug)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconcept_drift_detected\u001B[39m(\n\u001B[0;32m    118\u001B[0m         ref_window,\n\u001B[0;32m    119\u001B[0m         test_window,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    126\u001B[0m         debug\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    127\u001B[0m ):\n\u001B[0;32m    128\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;124;03m    Detect whether a concept drift occurred based on one reference and one testing window\u001B[39;00m\n\u001B[0;32m    130\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;124;03m    :return: true if drift is detected based on the two windows, false otherwise\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m    142\u001B[0m     ref_plus, ref_minus, test_plus, test_minus \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m--> 143\u001B[0m         \u001B[43mjoin_predict_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mref_window\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_window\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mn_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_init\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debug: \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBETA MINUS (ref+, ref-, test-)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    147\u001B[0m     beta_minus, beta_minus_additional \u001B[38;5;241m=\u001B[39m compute_beta(\n\u001B[0;32m    148\u001B[0m         ref_plus, ref_minus, test_minus)\n",
      "File \u001B[1;32m~\\PycharmProjects\\clustering-drift-detection\\ucdd_improved\\core\\ucdd.py:63\u001B[0m, in \u001B[0;36mjoin_predict_split\u001B[1;34m(ref_window, test_window, n_init, max_iter, tol, random_state)\u001B[0m\n\u001B[0;32m     58\u001B[0m window_union \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack((ref_window, test_window))\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# print('n_init', n_init, 'max_iter', max_iter, 'tol', tol)\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \n\u001B[0;32m     62\u001B[0m \u001B[38;5;66;03m# predict their label values\u001B[39;00m\n\u001B[1;32m---> 63\u001B[0m predicted_labels \u001B[38;5;241m=\u001B[39m \u001B[43mKMeans\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_init\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m)\u001B[49m\u001B[43m\\\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwindow_union\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;66;03m# split values by predicted label and window\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m split_back_to_windows(window_union, predicted_labels, ref_window\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], test_window\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[1;32mc:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:996\u001B[0m, in \u001B[0;36m_BaseKMeans.fit_predict\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    974\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001B[39;00m\n\u001B[0;32m    975\u001B[0m \n\u001B[0;32m    976\u001B[0m \u001B[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    994\u001B[0m \u001B[38;5;124;03m        Index of the cluster each sample belongs to.\u001B[39;00m\n\u001B[0;32m    995\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 996\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mlabels_\n",
      "File \u001B[1;32mc:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1410\u001B[0m, in \u001B[0;36mKMeans.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1406\u001B[0m best_inertia, best_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1408\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_init):\n\u001B[0;32m   1409\u001B[0m     \u001B[38;5;66;03m# Initialize centers\u001B[39;00m\n\u001B[1;32m-> 1410\u001B[0m     centers_init \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_centroids\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_squared_norms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m   1412\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1413\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[0;32m   1414\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitialization complete\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mc:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:952\u001B[0m, in \u001B[0;36m_BaseKMeans._init_centroids\u001B[1;34m(self, X, x_squared_norms, init, random_state, init_size, n_centroids)\u001B[0m\n\u001B[0;32m    949\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(init, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m init \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk-means++\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 952\u001B[0m     centers, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_kmeans_plusplus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    953\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    954\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    955\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    956\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx_squared_norms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    957\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    958\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(init, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m init \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    959\u001B[0m     seeds \u001B[38;5;241m=\u001B[39m random_state\u001B[38;5;241m.\u001B[39mpermutation(n_samples)[:n_clusters]\n",
      "File \u001B[1;32mc:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:209\u001B[0m, in \u001B[0;36m_kmeans_plusplus\u001B[1;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001B[0m\n\u001B[0;32m    206\u001B[0m indices[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m center_id\n\u001B[0;32m    208\u001B[0m \u001B[38;5;66;03m# Initialize list of closest distances and calculate current potential\u001B[39;00m\n\u001B[1;32m--> 209\u001B[0m closest_dist_sq \u001B[38;5;241m=\u001B[39m \u001B[43m_euclidean_distances\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcenters\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnewaxis\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_norm_squared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msquared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m    211\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m current_pot \u001B[38;5;241m=\u001B[39m closest_dist_sq\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m    214\u001B[0m \u001B[38;5;66;03m# Pick the remaining n_clusters-1 points\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:372\u001B[0m, in \u001B[0;36m_euclidean_distances\u001B[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001B[0m\n\u001B[0;32m    370\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m XX\n\u001B[0;32m    371\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m YY\n\u001B[1;32m--> 372\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaximum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdistances\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001B[39;00m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001B[39;00m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m Y:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from core import ucdd_eval\n",
    "\n",
    "\n",
    "sea_stats = {}\n",
    "for sea_path in all_sea_data_paths:\n",
    "    runs_results_bool, final_fpr_mean, fpr_std_err, final_latency_mean, latency_std_err = \\\n",
    "        ucdd_eval.all_drifting_batches_randomness_robust(\n",
    "        sea_reference_batches[sea_path],\n",
    "        sea_testing_batches[sea_path],\n",
    "        min_ref_batches_drift=0.3,\n",
    "        additional_check=True,\n",
    "        n_init=100,\n",
    "        max_iter=77000,\n",
    "        tol=0,\n",
    "        true_drift_idx=2,\n",
    "        min_runs=2\n",
    "    )\n",
    "    sea_stats[sea_path] = {\n",
    "        'runs_results_bool': runs_results_bool,\n",
    "        'final_fpr_mean': final_fpr_mean,\n",
    "        'fpr_std_err': fpr_std_err,\n",
    "        'final_latency_mean': final_latency_mean,\n",
    "        'latency_std_err': latency_std_err\n",
    "    }\n",
    "\n",
    "print('SEA STATS')\n",
    "print(sea_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_helpers import helpers\n",
    "\n",
    "\n",
    "final_result_dict = {\n",
    "    'type_of_data': [], 'dataset': [], 'drift': [], 'width': [], 'encoding': [],\n",
    "    'min_ref_batches_drift': [], 'additional_check': [],\n",
    "    'n_init': [], 'max_iter': [], 'tol': [],\n",
    "    'FPR_mean': [], 'latency_mean': []\n",
    "}\n",
    "\n",
    "for data_path, stats_dict in sea_stats.items():\n",
    "#     data_filename = data_path.split('/')[-1]\n",
    "#     type_of_data = data_path.split('/')[2].split('_')[0]  # synthetic or real-world\n",
    "#     dataset_name = data_filename.split('_')[0]  # sea, agraw1, agraw2\n",
    "#     drift_type = data_path.split('/')[3].split('_')[0]\n",
    "#     drift_width = '0' if drift_type == 'abrupt' else data_filename.split('_')[-1].split('.')[0]\n",
    "#     drift_width = 0.5 if drift_width == '05' else float(drift_width)\n",
    "    synthetic_filename_info = helpers.synthetic_data_information(data_path)\n",
    "    encoding = 'exclude'\n",
    "    fpr_mean = float(stats_dict['final_fpr_mean'])\n",
    "    latency_mean = float(stats_dict['final_latency_mean'])\n",
    "    \n",
    "    final_result_dict['type_of_data'].append(synthetic_filename_info['type_of_data'])\n",
    "    final_result_dict['dataset'].append(synthetic_filename_info['dataset_name'])\n",
    "    final_result_dict['drift'].append(synthetic_filename_info['drift_type'])\n",
    "    final_result_dict['width'].append(synthetic_filename_info['drift_width'])\n",
    "    final_result_dict['encoding'].append(encoding)\n",
    "    final_result_dict['min_ref_batches_drift'].append(0.3)\n",
    "    final_result_dict['additional_check'].append('yes')\n",
    "    final_result_dict['n_init'].append(100)\n",
    "    final_result_dict['max_iter'].append(550)\n",
    "    final_result_dict['tol'].append(0)\n",
    "    final_result_dict['FPR_mean'].append(fpr_mean)\n",
    "    final_result_dict['latency_mean'].append(latency_mean)\n",
    "    \n",
    "final_result_df = pd.DataFrame.from_dict(final_result_dict)\n",
    "sorted_final_result_df = final_result_df.sort_values(['drift', 'dataset', 'encoding', 'width'])\n",
    "final_result_df.to_csv('sea_jupyter_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}