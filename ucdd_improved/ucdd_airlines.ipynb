{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# UCDD on airlines evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Accept and preprocess the airlines dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique airlines 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\category_encoders\\target_encoder.py:122: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\category_encoders\\target_encoder.py:127: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reference data shape\n",
      "exclude\n",
      "(179794, 3)\n",
      "onehot\n",
      "(179794, 21)\n",
      "target\n",
      "(179794, 4)\n",
      "\n",
      "reference labels shape\n",
      "(179794, 1)\n",
      "\n",
      "testing data shape\n",
      "exclude\n",
      "(359589, 3)\n",
      "onehot\n",
      "(359589, 21)\n",
      "target\n",
      "(359589, 4)\n",
      "\n",
      "testing labels shape\n",
      "(359589, 1)\n"
     ]
    }
   ],
   "source": [
    "from eval_helpers import accepting\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "airlines_exclude_reference_batches = []\n",
    "airlines_exclude_testing_batches = []\n",
    "airlines_onehot_reference_batches = []\n",
    "airlines_onehot_testing_batches = []\n",
    "airlines_target_reference_batches = []\n",
    "airlines_target_testing_batches = []\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../Datasets_concept_drift/real_world_data/airline_dataset.csv\")\n",
    "\n",
    "X = df.drop(columns=['Unnamed: 0', 'Delay'])\n",
    "y = df[\"Delay\"]\n",
    "\n",
    "print('number of unique airlines', df['Airline'].nunique())\n",
    "\n",
    "X_ref = X[:179794]\n",
    "X_test = X[179794:]\n",
    "y_ref = y[:179794]\n",
    "y_test = y[179794:]\n",
    "\n",
    "df_x_ref_num, df_x_ref_cat = accepting.divide_numeric_categorical(X_ref)\n",
    "df_x_test_num, df_x_test_cat = accepting.divide_numeric_categorical(X_test)\n",
    "\n",
    "X_ref_exclude = df_x_ref_num.to_numpy()\n",
    "X_test_exclude = df_x_test_num.to_numpy()\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_ref_exclude)\n",
    "X_ref_exclude = scaler.transform(X_ref_exclude)\n",
    "X_test_exclude = scaler.transform(X_test_exclude)\n",
    "\n",
    "ref_index = df_x_ref_cat.index\n",
    "test_index = df_x_test_cat.index\n",
    "encoder = TargetEncoder()\n",
    "encoder.fit(df_x_ref_cat, y_ref)\n",
    "df_x_ref_cat_transformed = pd.DataFrame(encoder.transform(df_x_ref_cat))\n",
    "df_x_test_cat_transformed = pd.DataFrame(encoder.transform(df_x_test_cat))\n",
    "df_x_ref_cat_transformed.set_index(ref_index, inplace=True)\n",
    "df_x_test_cat_transformed.set_index(test_index, inplace=True)\n",
    "X_ref_target = df_x_ref_num.join(df_x_ref_cat_transformed, lsuffix='_num').to_numpy()\n",
    "X_test_target = df_x_test_num.join(df_x_test_cat_transformed, lsuffix='_num').to_numpy()\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_ref_target)\n",
    "X_ref_target = scaler.transform(X_ref_target)\n",
    "X_test_target = scaler.transform(X_test_target)\n",
    "\n",
    "ref_index = df_x_ref_cat.index\n",
    "test_index = df_x_test_cat.index\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder.fit(df_x_ref_cat)\n",
    "df_x_ref_cat_transformed = pd.DataFrame(encoder.transform(df_x_ref_cat))\n",
    "df_x_test_cat_transformed = pd.DataFrame(encoder.transform(df_x_test_cat))\n",
    "df_x_ref_cat_transformed.set_index(ref_index, inplace=True)\n",
    "df_x_test_cat_transformed.set_index(test_index, inplace=True)\n",
    "X_ref_onehot = df_x_ref_num.join(df_x_ref_cat_transformed, lsuffix='_num').to_numpy()\n",
    "X_test_onehot = df_x_test_num.join(df_x_test_cat_transformed, lsuffix='_num').to_numpy()\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_ref_onehot)\n",
    "X_ref_onehot = scaler.transform(X_ref_onehot)\n",
    "X_test_onehot = scaler.transform(X_test_onehot)\n",
    "\n",
    "y_ref = y_ref.to_numpy().reshape((len(y_ref.index), 1))\n",
    "y_test = y_test.to_numpy().reshape((len(y_test.index), 1))\n",
    "\n",
    "print('\\nreference data shape')\n",
    "print('exclude')\n",
    "print(X_ref_exclude.shape)\n",
    "print('onehot')\n",
    "print(X_ref_onehot.shape)\n",
    "print('target')\n",
    "print(X_ref_target.shape)\n",
    "\n",
    "print('\\nreference labels shape')\n",
    "print(y_ref.shape)\n",
    "\n",
    "print('\\ntesting data shape')\n",
    "print('exclude')\n",
    "print(X_test_exclude.shape)\n",
    "print('onehot')\n",
    "print(X_test_onehot.shape)\n",
    "print('target')\n",
    "print(X_test_target.shape)\n",
    "\n",
    "print('\\ntesting labels shape')\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data to batches (size=17000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79736303 0.46256123 0.05496183]\n",
      " [0.8766001  0.46256123 0.05801527]\n",
      " [0.89247312 0.46256123 0.22748092]\n",
      " ...\n",
      " [0.12839222 0.563331   0.22137405]\n",
      " [0.15245776 0.563331   0.24427481]\n",
      " [0.20302099 0.563331   0.08396947]]\n",
      "(17000, 3)\n",
      "[[0.0343062  0.00349895 0.3129771 ]\n",
      " [0.19930876 0.00349895 0.3389313 ]\n",
      " [0.30709165 0.0069979  0.2519084 ]\n",
      " ...\n",
      " [0.42524322 0.88523443 0.18320611]\n",
      " [0.28046595 0.88523443 0.12977099]\n",
      " [0.38082437 0.88523443 0.17251908]]\n",
      "(17000, 3)\n",
      "[[0.79736303 0.46256123 0.05496183 ... 0.         0.         0.        ]\n",
      " [0.8766001  0.46256123 0.05801527 ... 0.         0.         0.        ]\n",
      " [0.89247312 0.46256123 0.22748092 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.12839222 0.563331   0.22137405 ... 0.         0.         0.        ]\n",
      " [0.15245776 0.563331   0.24427481 ... 0.         0.         0.        ]\n",
      " [0.20302099 0.563331   0.08396947 ... 0.         0.         0.        ]]\n",
      "(17000, 21)\n",
      "[[0.0343062  0.00349895 0.3129771  ... 0.         0.         0.        ]\n",
      " [0.19930876 0.00349895 0.3389313  ... 0.         0.         0.        ]\n",
      " [0.30709165 0.0069979  0.2519084  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.42524322 0.88523443 0.18320611 ... 1.         0.         0.        ]\n",
      " [0.28046595 0.88523443 0.12977099 ... 0.         1.         0.        ]\n",
      " [0.38082437 0.88523443 0.17251908 ... 0.         1.         0.        ]]\n",
      "(17000, 21)\n",
      "[[0.79736303 0.46256123 0.05496183 0.4817961 ]\n",
      " [0.8766001  0.46256123 0.05801527 0.4817961 ]\n",
      " [0.89247312 0.46256123 0.22748092 0.4817961 ]\n",
      " ...\n",
      " [0.12839222 0.563331   0.22137405 0.36543251]\n",
      " [0.15245776 0.563331   0.24427481 0.36543251]\n",
      " [0.20302099 0.563331   0.08396947 0.36543251]]\n",
      "(17000, 4)\n",
      "[[0.0343062  0.00349895 0.3129771  0.65821603]\n",
      " [0.19930876 0.00349895 0.3389313  0.22004826]\n",
      " [0.30709165 0.0069979  0.2519084  0.36543251]\n",
      " ...\n",
      " [0.42524322 0.88523443 0.18320611 1.        ]\n",
      " [0.28046595 0.88523443 0.12977099 0.26603767]\n",
      " [0.38082437 0.88523443 0.17251908 0.26603767]]\n",
      "(17000, 4)\n",
      "number of resulting testing batches\n",
      "exclude\n",
      "21\n",
      "onehot\n",
      "21\n",
      "target\n",
      "21\n",
      "labels\n",
      "21\n",
      "number of resulting reference batches\n",
      "exclude\n",
      "10\n",
      "onehot\n",
      "10\n",
      "target\n",
      "10\n",
      "labels\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from eval_helpers import helpers\n",
    "import importlib\n",
    "importlib.reload(helpers)\n",
    "\n",
    "X_test_batches_exclude, y_test_batches = helpers.split_to_fixed_size_batches(X_test_exclude, y_test, batch_size=17000)\n",
    "X_ref_batches_exclude, y_ref_batches = helpers.split_to_fixed_size_batches(X_ref_exclude, y_ref, batch_size=17000)\n",
    "X_test_batches_onehot, _ = helpers.split_to_fixed_size_batches(X_test_onehot, y_test, batch_size=17000)\n",
    "X_ref_batches_onehot, _ = helpers.split_to_fixed_size_batches(X_ref_onehot, y_ref, batch_size=17000)\n",
    "X_test_batches_target, _ = helpers.split_to_fixed_size_batches(X_test_target, y_test, batch_size=17000)\n",
    "X_ref_batches_target, _ = helpers.split_to_fixed_size_batches(X_ref_target, y_ref, batch_size=17000)\n",
    "\n",
    "print('number of resulting testing batches')\n",
    "print('exclude')\n",
    "print(len(X_test_batches_exclude))\n",
    "print('onehot')\n",
    "print(len(X_test_batches_onehot))\n",
    "print('target')\n",
    "print(len(X_test_batches_target))\n",
    "print('labels')\n",
    "print(len(y_test_batches))\n",
    "\n",
    "print('number of resulting reference batches')\n",
    "print('exclude')\n",
    "print(len(X_ref_batches_exclude))\n",
    "print('onehot')\n",
    "print(len(X_ref_batches_onehot))\n",
    "print('target')\n",
    "print(len(X_ref_batches_target))\n",
    "print('labels')\n",
    "print(len(y_ref_batches))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something\n"
     ]
    },
    {
     "data": {
      "text/plain": "<module 'eval_helpers.kmeans_verbose_helpers' from 'C:\\\\Users\\\\jpohl\\\\PycharmProjects\\\\clustering-drift-detection\\\\ucdd_improved\\\\eval_helpers\\\\kmeans_verbose_helpers.py'>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from eval_helpers import ucdd_eval_real_world\n",
    "from eval_helpers import kmeans_verbose_helpers\n",
    "from core import ucdd_supported_parameters as spms\n",
    "from core import ucdd\n",
    "importlib.reload(ucdd_eval_real_world)\n",
    "importlib.reload(ucdd)\n",
    "importlib.reload(kmeans_verbose_helpers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments with target encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find suitable KMeans clustering parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename airlines_kmeans_target/airlines_kmeans_target_output0.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_target/airlines_kmeans_target_output1.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_target/airlines_kmeans_target_output2.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_target/airlines_kmeans_target_output3.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_target/airlines_kmeans_target_output4.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_target/airlines_kmeans_target_output5.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_target/airlines_kmeans_target_output6.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_target/airlines_kmeans_target_output7.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_target/airlines_kmeans_target_output8.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_target/airlines_kmeans_target_output9.txt\n",
      "random state: 1053\n",
      "{'total_max_iterations': 42, 'total_min_init_inertia': 4637.488648502701, 'total_max_init_inertia': 12548.678845293836, 'total_min_final_inertia': 4296.967267770373, 'total_max_final_inertia': 5039.664439430261, 'total_num_convergences': 1000, 'total_num_strict_convergences': 1000, 'total_num_tol_based_convergences': 0}\n"
     ]
    }
   ],
   "source": [
    "kmeans_verbose_helpers.write_kmeans_results_ucdd_helper('airlines_kmeans_target/airlines_kmeans_target_output',\n",
    "                                                        X_ref_batches_target,\n",
    "                                                        n_init=100, max_iter=500, tol=0, random_state=1053)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use UCDD directly to obtain inspectable results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state\n",
      "0\n",
      "pool opened\n",
      "random_state\n",
      "100\n",
      "pool opened\n"
     ]
    }
   ],
   "source": [
    "from core import ucdd\n",
    "import importlib\n",
    "importlib.reload(ucdd)\n",
    "\n",
    "all_2d_drifts_target = []\n",
    "all_2d_cluster_classif_accs_target = []\n",
    "\n",
    "for random_state in [0, 100]:\n",
    "    drifts_2d_arr_target, cluster_classif_accs_2d_arr_target = ucdd.all_drifting_batches_parallel_all_info(\n",
    "        X_ref_batches_target,\n",
    "        X_test_batches_target,\n",
    "        additional_check=True,\n",
    "        n_init=100,\n",
    "        max_iter=42000,\n",
    "        tol=0,\n",
    "        random_state=random_state,\n",
    "        reference_label_batches=y_ref_batches,\n",
    "        testing_label_batches=y_test_batches\n",
    "    )\n",
    "    all_2d_drifts_target.append(drifts_2d_arr_target)\n",
    "    all_2d_cluster_classif_accs_target.append(cluster_classif_accs_2d_arr_target)\n",
    "\n",
    "result_dict_target = {\n",
    "    'all_2d_drifts_target': all_2d_drifts_target,\n",
    "    'all_2d_cluster_classif_accs_target': all_2d_cluster_classif_accs_target\n",
    "}\n",
    "np.save('airlines_stats_target.npy', result_dict_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of drift detections: 210\n",
      "number of drift detection differences in the two runs:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "result_dict_target = np.load('airlines_stats_target.npy', allow_pickle=True).item()\n",
    "all_2d_drifts_target = result_dict_target['all_2d_drifts_target']\n",
    "print('total number of drift detections:', len(X_ref_batches_target) * len(X_test_batches_target))\n",
    "print('number of drift detection differences in the two runs:')\n",
    "num_diffs = np.sum(all_2d_drifts_target[0] != all_2d_drifts_target[1])\n",
    "print(num_diffs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use them for the evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state\n",
      "0\n",
      "random_state\n",
      "100\n",
      "target detection list\n",
      "[[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False], [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False]]\n",
      "execution time\n",
      "229.92048907279968\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from ucdd_improved.core import ucdd\n",
    "import csv\n",
    "importlib.reload(ucdd)\n",
    "\n",
    "# # because of time constraints, only use 20% of all reference batches\n",
    "# print('number of reference batches')\n",
    "# print(len(X_ref_batches_target))\n",
    "# num_ref_batches_to_use = int(0.2 * len(X_ref_batches_target))\n",
    "#\n",
    "# random.seed(0)\n",
    "# X_ref_batches_target_choice = random.sample(X_ref_batches_target, num_ref_batches_to_use)\n",
    "# print('number of batches in the choice')\n",
    "# print(len(X_ref_batches_target_choice))\n",
    "# print(X_ref_batches_target_choice)\n",
    "\n",
    "target_detection_list = []\n",
    "start_time = time.time()\n",
    "for first_random_state in [0, 100]:\n",
    "    drifts_detected = ucdd.all_drifting_batches_parallel(\n",
    "        X_ref_batches_target,\n",
    "        X_test_batches_target,\n",
    "        min_ref_batches_drift=0.3,\n",
    "        additional_check=True,\n",
    "        n_init=100,\n",
    "        max_iter=42000,\n",
    "        tol=0,\n",
    "        random_state=first_random_state\n",
    "    )\n",
    "    target_detection_list.append(drifts_detected)\n",
    "\n",
    "print('target detection list')\n",
    "print(target_detection_list)\n",
    "print('execution time')\n",
    "print(time.time() - start_time)\n",
    "with open('airlines_target.csv', 'w') as f:\n",
    "    wrtr = csv.writer(f)\n",
    "    wrtr.writerows(target_detection_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments with onehot encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find suitable KMeans clustering parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output0.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output1.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output2.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output3.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output4.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output5.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output6.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output7.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output8.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_onehot/airlines_kmeans_onehot_output9.txt\n",
      "random state: 1053\n",
      "{'total_max_iterations': 16, 'total_min_init_inertia': 51567.30607214207, 'total_max_init_inertia': 71575.79111583055, 'total_min_final_inertia': 29377.130552877377, 'total_max_final_inertia': 33896.98754005208, 'total_num_convergences': 1000, 'total_num_strict_convergences': 1000, 'total_num_tol_based_convergences': 0}\n"
     ]
    }
   ],
   "source": [
    "kmeans_verbose_helpers.write_kmeans_results_ucdd_helper('airlines_kmeans_onehot/airlines_kmeans_onehot_output',\n",
    "                                                        X_ref_batches_onehot,\n",
    "                                                        n_init=100, max_iter=500, tol=0, random_state=1053)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use UCDD directly to obtain inspectable results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state\n",
      "0\n",
      "pool opened\n",
      "random_state\n",
      "100\n",
      "pool opened\n"
     ]
    }
   ],
   "source": [
    "from core import ucdd\n",
    "import importlib\n",
    "importlib.reload(ucdd)\n",
    "\n",
    "all_2d_drifts_onehot = []\n",
    "all_2d_cluster_classif_accs_onehot = []\n",
    "\n",
    "for random_state in [0, 100]:\n",
    "    drifts_2d_arr_onehot, cluster_classif_accs_2d_arr_onehot = ucdd.all_drifting_batches_parallel_all_info(\n",
    "        X_ref_batches_onehot,\n",
    "        X_test_batches_onehot,\n",
    "        additional_check=True,\n",
    "        n_init=100,\n",
    "        max_iter=16000,\n",
    "        tol=0,\n",
    "        random_state=random_state,\n",
    "        reference_label_batches=y_ref_batches,\n",
    "        testing_label_batches=y_test_batches\n",
    "    )\n",
    "    all_2d_drifts_onehot.append(drifts_2d_arr_onehot)\n",
    "    all_2d_cluster_classif_accs_onehot.append(cluster_classif_accs_2d_arr_onehot)\n",
    "\n",
    "result_dict_onehot = {\n",
    "    'all_2d_drifts_onehot': all_2d_drifts_onehot,\n",
    "    'all_2d_cluster_classif_accs_onehot': all_2d_cluster_classif_accs_onehot\n",
    "}\n",
    "np.save('airlines_stats_onehot.npy', result_dict_onehot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of drift detections: 210\n",
      "number of drift detection differences in the two runs:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "result_dict_onehot = np.load('airlines_stats_onehot.npy', allow_pickle=True).item()\n",
    "all_2d_drifts_onehot = result_dict_onehot['all_2d_drifts_onehot']\n",
    "print('total number of drift detections:', len(X_ref_batches_onehot) * len(X_test_batches_onehot))\n",
    "print('number of drift detection differences in the two runs:')\n",
    "num_diffs = np.sum(all_2d_drifts_onehot[0] != all_2d_drifts_onehot[1])\n",
    "print(num_diffs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use them for the evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state\n",
      "0\n",
      "random_state\n",
      "100\n",
      "onehot detection list\n",
      "[[False, False, False, False, False, False, True, True, False, True, False, False, False, True, True, True, False, False, False, False, False], [False, False, False, False, False, False, True, True, False, True, False, False, False, True, True, True, False, False, False, False, False]]\n",
      "execution time\n",
      "282.94530868530273\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from ucdd_improved.core import ucdd\n",
    "import csv\n",
    "importlib.reload(ucdd)\n",
    "\n",
    "# # because of time constraints, only use 20% of all reference batches\n",
    "# print('number of reference batches')\n",
    "# print(len(X_ref_batches_onehot))\n",
    "# num_ref_batches_to_use = int(0.2 * len(X_ref_batches_onehot))\n",
    "#\n",
    "# random.seed(0)\n",
    "# X_ref_batches_onehot_choice = random.sample(X_ref_batches_onehot, num_ref_batches_to_use)\n",
    "# print('number of batches in the choice')\n",
    "# print(len(X_ref_batches_onehot_choice))\n",
    "# print(X_ref_batches_onehot_choice)\n",
    "\n",
    "onehot_detection_list = []\n",
    "start_time = time.time()\n",
    "for first_random_state in [0, 100]:\n",
    "    drifts_detected = ucdd.all_drifting_batches_parallel(\n",
    "        X_ref_batches_onehot,\n",
    "        X_test_batches_onehot,\n",
    "        min_ref_batches_drift=0.3,\n",
    "        additional_check=True,\n",
    "        n_init=100,\n",
    "        max_iter=16000,\n",
    "        tol=0,\n",
    "        random_state=first_random_state\n",
    "    )\n",
    "    onehot_detection_list.append(drifts_detected)\n",
    "\n",
    "print('onehot detection list')\n",
    "print(onehot_detection_list)\n",
    "print('execution time')\n",
    "print(time.time() - start_time)\n",
    "with open('airlines_onehot.csv', 'w') as f:\n",
    "    wrtr = csv.writer(f)\n",
    "    wrtr.writerows(onehot_detection_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments with excluded categories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find suitable KMeans clustering parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output0.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output1.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output2.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output3.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output4.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output5.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output6.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output7.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output8.txt\n",
      "random state: 1053\n",
      "filename airlines_kmeans_exclude/airlines_kmeans_exclude_output9.txt\n",
      "random state: 1053\n",
      "{'total_max_iterations': 24, 'total_min_init_inertia': 2193.374855109041, 'total_max_init_inertia': 8673.080383545612, 'total_min_final_inertia': 2062.897163906888, 'total_max_final_inertia': 2255.1812155416997, 'total_num_convergences': 1000, 'total_num_strict_convergences': 1000, 'total_num_tol_based_convergences': 0}\n"
     ]
    }
   ],
   "source": [
    "kmeans_verbose_helpers.write_kmeans_results_ucdd_helper('airlines_kmeans_exclude/airlines_kmeans_exclude_output',\n",
    "                                                        X_ref_batches_exclude,\n",
    "                                                        n_init=100, max_iter=500, tol=0, random_state=1053)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use UCDD directly to obtain inspectable results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state\n",
      "0\n",
      "pool opened\n",
      "random_state\n",
      "100\n",
      "pool opened\n"
     ]
    }
   ],
   "source": [
    "from core import ucdd\n",
    "import importlib\n",
    "importlib.reload(ucdd)\n",
    "\n",
    "all_2d_drifts_exclude = []\n",
    "all_2d_cluster_classif_accs_exclude = []\n",
    "\n",
    "for random_state in [0, 100]:\n",
    "    drifts_2d_arr_exclude, cluster_classif_accs_2d_arr_exclude = ucdd.all_drifting_batches_parallel_all_info(\n",
    "        X_ref_batches_exclude,\n",
    "        X_test_batches_exclude,\n",
    "        additional_check=True,\n",
    "        n_init=5,\n",
    "        # n_init=100,\n",
    "        max_iter=20,\n",
    "        tol=0,\n",
    "        random_state=random_state,\n",
    "        reference_label_batches=y_ref_batches,\n",
    "        testing_label_batches=y_test_batches\n",
    "    )\n",
    "    all_2d_drifts_exclude.append(drifts_2d_arr_exclude)\n",
    "    all_2d_cluster_classif_accs_exclude.append(cluster_classif_accs_2d_arr_exclude)\n",
    "\n",
    "result_dict_exclude = {\n",
    "    'all_2d_drifts_exclude': all_2d_drifts_exclude,\n",
    "    'all_2d_cluster_classif_accs_exclude': all_2d_cluster_classif_accs_exclude\n",
    "}\n",
    "np.save('airlines_stats_exclude.npy', result_dict_exclude)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of drift detections: 210\n",
      "number of drift detection differences in the two runs:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "result_dict_exclude = np.load('airlines_stats_exclude.npy', allow_pickle=True).item()\n",
    "all_2d_drifts_exclude = result_dict_exclude['all_2d_drifts_exclude']\n",
    "print('total number of drift detections:', len(X_ref_batches_exclude) * len(X_test_batches_exclude))\n",
    "print('number of drift detection differences in the two runs:')\n",
    "num_diffs = np.sum(all_2d_drifts_exclude[0] != all_2d_drifts_exclude[1])\n",
    "print(num_diffs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use them for the evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state\n",
      "0\n",
      "random_state\n",
      "100\n",
      "exclude detection list\n",
      "[[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False], [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]]\n",
      "execution time\n",
      "177.9049210548401\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from ucdd_improved.core import ucdd\n",
    "import csv\n",
    "importlib.reload(ucdd)\n",
    "\n",
    "# # because of time constraints, only use 20% of all reference batches\n",
    "# print('number of reference batches')\n",
    "# print(len(X_ref_batches_exclude))\n",
    "# num_ref_batches_to_use = int(0.2 * len(X_ref_batches_exclude))\n",
    "#\n",
    "# random.seed(0)\n",
    "# X_ref_batches_exclude_choice = random.sample(X_ref_batches_exclude, num_ref_batches_to_use)\n",
    "# print('number of batches in the choice')\n",
    "# print(len(X_ref_batches_exclude_choice))\n",
    "# print(X_ref_batches_exclude_choice)\n",
    "\n",
    "exclude_detection_list = []\n",
    "start_time = time.time()\n",
    "for first_random_state in [0, 100]:\n",
    "    drifts_detected = ucdd.all_drifting_batches_parallel(\n",
    "        X_ref_batches_exclude,\n",
    "        X_test_batches_exclude,\n",
    "        min_ref_batches_drift=0.3,\n",
    "        additional_check=True,\n",
    "        n_init=100,\n",
    "        max_iter=24000,\n",
    "        tol=0,\n",
    "        random_state=first_random_state\n",
    "    )\n",
    "    exclude_detection_list.append(drifts_detected)\n",
    "\n",
    "print('exclude detection list')\n",
    "print(exclude_detection_list)\n",
    "print('execution time')\n",
    "print(time.time() - start_time)\n",
    "with open('airlines_exclude.csv', 'w') as f:\n",
    "    wrtr = csv.writer(f)\n",
    "    wrtr.writerows(exclude_detection_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}