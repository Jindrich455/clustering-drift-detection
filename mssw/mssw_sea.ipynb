{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation of MSSW on SEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEA dataset locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "abrupt_sea_path = '../Datasets_concept_drift/synthetic_data/abrupt_drift/sea_1_abrupt_drift_0_noise_balanced.arff'\n",
    "gradual_sea_paths = [\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_05.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_1.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_5.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_10.arff',\n",
    "    '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_20.arff'\n",
    "]\n",
    "all_sea_data_paths = [abrupt_sea_path] + gradual_sea_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accept and preprocess SEA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  4.636430  6.639370  0.066740  b'groupB'\n",
      "99996  4.251993  3.351235  5.652197  b'groupA'\n",
      "99997  4.131405  6.371722  3.125554  b'groupB'\n",
      "99998  1.404214  4.392506  9.298558  b'groupA'\n",
      "99999  7.231749  8.770465  3.925490  b'groupB'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\mssw\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df         attrib1   attrib2   attrib3      class\n",
      "0      7.308782  4.100808  2.077148  b'groupB'\n",
      "1      5.833539  0.422983  7.616747  b'groupA'\n",
      "2      1.397627  6.949480  8.052278  b'groupB'\n",
      "3      2.750299  0.753878  6.105915  b'groupA'\n",
      "4      2.049135  6.233638  1.847071  b'groupB'\n",
      "...         ...       ...       ...        ...\n",
      "99995  2.074508  1.775662  1.318589  b'groupA'\n",
      "99996  4.636430  6.639370  0.066740  b'groupB'\n",
      "99997  4.251993  3.351235  5.652197  b'groupA'\n",
      "99998  4.131405  6.371722  3.125554  b'groupB'\n",
      "99999  1.404214  4.392506  9.298558  b'groupA'\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpohl\\PycharmProjects\\clustering-drift-detection\\mssw\\accepting.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.decode('utf-8')\n",
      "c:\\users\\jpohl\\pycharmprojects\\clustering-drift-detection\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import accepting\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sea_reference_batches = {}\n",
    "sea_testing_batches = {}\n",
    "for sea_path in all_sea_data_paths:\n",
    "    df_x, df_y = accepting.get_clean_df(sea_path)\n",
    "    df_y = pd.DataFrame(LabelEncoder().fit_transform(df_y))\n",
    "\n",
    "    df_x_ref, df_x_test, df_y_ref, df_y_test = sklearn.model_selection.train_test_split(\n",
    "        df_x, df_y, test_size=0.7, shuffle=False)\n",
    "    \n",
    "    reference_data = df_x_ref.to_numpy()\n",
    "    testing_data = df_x_test.to_numpy()\n",
    "    num_ref_batches = 3\n",
    "    num_test_batches = 7\n",
    "    ref_batches = np.array_split(reference_data, num_ref_batches)\n",
    "    test_batches = np.array_split(testing_data, num_test_batches)\n",
    "    \n",
    "    sea_reference_batches[sea_path] = ref_batches\n",
    "    sea_testing_batches[sea_path] = test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best tol and max_iter in SEA (the drift type is irrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state: 1053\n",
      "total number of results: 100\n",
      "maximum number of iterations: 54\n",
      "minimum initial inertia: 657.5117945560726\n",
      "maximum initial inertia: 1654.92779186788\n",
      "number of unique final inertia values: 17\n",
      "minimum final inertia: 597.8461904607495\n",
      "maximum final inertia: 605.4169667607526\n",
      "total number of convergences: 100\n",
      "number of strict convergences: 100\n",
      "number of tol-based convergences: 0\n"
     ]
    }
   ],
   "source": [
    "import mssw_preprocessing\n",
    "import kmeans_verbose_helpers\n",
    "\n",
    "\n",
    "weighted_joined_reference_data, _, _ = mssw_preprocessing.mssw_preprocess(\n",
    "    sea_reference_batches[abrupt_sea_path], sea_testing_batches[abrupt_sea_path])\n",
    "\n",
    "filename = 'sea_new_output.txt'\n",
    "kmeans_verbose_helpers.write_verbose_kmeans_to_file(filename, weighted_joined_reference_data,\n",
    "                             n_clusters=2, n_init=100, max_iter=500, tol=0, random_state=1053)\n",
    "output_dicts = kmeans_verbose_helpers.convert_kmeans_output_file_to_dicts(filename, n_init=100)\n",
    "kmeans_verbose_helpers.print_stats_from_kmeans_output_dicts(output_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use them for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_runs 2\n",
      "centroid distance sums [[ 945.67719668 1356.42528063]]\n",
      "num points in clusters [[3795. 6205.]]\n",
      "centroid distance sums [[ 950.35491978 1335.33354816]]\n",
      "num points in clusters [[3864. 6136.]]\n",
      "centroid distance sums [[ 934.83093979 1350.55732975]]\n",
      "num points in clusters [[3792. 6208.]]\n",
      "centroid distance sums [[ 948.51413223 1343.04761502]]\n",
      "num points in clusters [[3836. 6164.]]\n",
      "centroid distance sums [[ 932.50752815 1362.37095108]]\n",
      "num points in clusters [[3753. 6247.]]\n",
      "centroid distance sums [[1095.37007132 1238.4956423 ]]\n",
      "num points in clusters [[4421. 5579.]]\n",
      "centroid distance sums [[1224.4535414  1169.54152057]]\n",
      "num points in clusters [[4921. 5079.]]\n",
      "centroid distance sums [[1216.65097587 1166.11643499]]\n",
      "num points in clusters [[4938. 5062.]]\n",
      "centroid distance sums [[1220.59723706 1160.67009289]]\n",
      "num points in clusters [[4911. 5089.]]\n",
      "centroid distance sums [[1232.38081469 1156.44808206]]\n",
      "num points in clusters [[4955. 5045.]]\n",
      "centroid distance sums [[1357.13848147  944.95695134]]\n",
      "num points in clusters [[6207. 3793.]]\n",
      "centroid distance sums [[1335.34858913  950.33428567]]\n",
      "num points in clusters [[6136. 3864.]]\n",
      "centroid distance sums [[1350.87083154  934.51895957]]\n",
      "num points in clusters [[6209. 3791.]]\n",
      "centroid distance sums [[1343.50559215  948.06154946]]\n",
      "num points in clusters [[6165. 3835.]]\n",
      "centroid distance sums [[1363.33236798  931.53707219]]\n",
      "num points in clusters [[6250. 3750.]]\n",
      "centroid distance sums [[1238.64170487 1095.19253302]]\n",
      "num points in clusters [[5580. 4420.]]\n",
      "centroid distance sums [[1169.53952199 1224.4501107 ]]\n",
      "num points in clusters [[5079. 4921.]]\n",
      "centroid distance sums [[1166.29858295 1216.45443928]]\n",
      "num points in clusters [[5063. 4937.]]\n",
      "centroid distance sums [[1161.16156963 1220.08898369]]\n",
      "num points in clusters [[5091. 4909.]]\n",
      "centroid distance sums [[1158.18812208 1230.62583858]]\n",
      "num points in clusters [[5050. 4950.]]\n",
      "min_runs 2\n",
      "centroid distance sums [[ 945.67719668 1356.42528063]]\n",
      "num points in clusters [[3795. 6205.]]\n",
      "centroid distance sums [[ 950.35491978 1335.33354816]]\n",
      "num points in clusters [[3864. 6136.]]\n",
      "centroid distance sums [[ 934.83093979 1350.55732975]]\n",
      "num points in clusters [[3792. 6208.]]\n",
      "centroid distance sums [[ 948.51413223 1343.04761502]]\n",
      "num points in clusters [[3836. 6164.]]\n",
      "centroid distance sums [[ 932.50752815 1362.37095108]]\n",
      "num points in clusters [[3753. 6247.]]\n",
      "centroid distance sums [[1095.1408339  1238.85077207]]\n",
      "num points in clusters [[4420. 5580.]]\n",
      "centroid distance sums [[1224.52649027 1169.54152057]]\n",
      "num points in clusters [[4921. 5079.]]\n",
      "centroid distance sums [[1216.80726443 1165.8097625 ]]\n",
      "num points in clusters [[4939. 5061.]]\n",
      "centroid distance sums [[1220.28354297 1160.97676538]]\n",
      "num points in clusters [[4910. 5090.]]\n",
      "centroid distance sums [[1232.54492434 1156.44808206]]\n",
      "num points in clusters [[4955. 5045.]]\n",
      "centroid distance sums [[1357.13848147  944.95695134]]\n",
      "num points in clusters [[6207. 3793.]]\n",
      "centroid distance sums [[1335.34858913  950.33428567]]\n",
      "num points in clusters [[6136. 3864.]]\n",
      "centroid distance sums [[1350.87083154  934.51895957]]\n",
      "num points in clusters [[6209. 3791.]]\n",
      "centroid distance sums [[1343.50559215  948.06154946]]\n",
      "num points in clusters [[6165. 3835.]]\n",
      "centroid distance sums [[1363.33236798  931.53707219]]\n",
      "num points in clusters [[6250. 3750.]]\n",
      "centroid distance sums [[1238.99673263 1094.96323321]]\n",
      "num points in clusters [[5581. 4419.]]\n",
      "centroid distance sums [[1169.53952199 1224.52305804]]\n",
      "num points in clusters [[5079. 4921.]]\n",
      "centroid distance sums [[1165.99184386 1216.61079175]]\n",
      "num points in clusters [[5062. 4938.]]\n",
      "centroid distance sums [[1161.46830872 1219.77545028]]\n",
      "num points in clusters [[5092. 4908.]]\n",
      "centroid distance sums [[1158.18812208 1230.78991138]]\n",
      "num points in clusters [[5050. 4950.]]\n",
      "min_runs 2\n",
      "centroid distance sums [[ 945.67719668 1356.42528063]]\n",
      "num points in clusters [[3795. 6205.]]\n",
      "centroid distance sums [[ 950.35491978 1335.33354816]]\n",
      "num points in clusters [[3864. 6136.]]\n",
      "centroid distance sums [[ 934.83093979 1350.55732975]]\n",
      "num points in clusters [[3792. 6208.]]\n",
      "centroid distance sums [[ 948.51413223 1343.04761502]]\n",
      "num points in clusters [[3836. 6164.]]\n",
      "centroid distance sums [[ 932.50752815 1362.37095108]]\n",
      "num points in clusters [[3753. 6247.]]\n",
      "centroid distance sums [[1095.13117777 1238.77735313]]\n",
      "num points in clusters [[4420. 5580.]]\n",
      "centroid distance sums [[1224.45708524 1169.81069859]]\n",
      "num points in clusters [[4920. 5080.]]\n",
      "centroid distance sums [[1217.08277265 1165.27595872]]\n",
      "num points in clusters [[4940. 5060.]]\n",
      "centroid distance sums [[1219.82407455 1161.48934287]]\n",
      "num points in clusters [[4909. 5091.]]\n",
      "centroid distance sums [[1232.69869215 1156.52324321]]\n",
      "num points in clusters [[4955. 5045.]]\n",
      "centroid distance sums [[1357.13848147  944.95695134]]\n",
      "num points in clusters [[6207. 3793.]]\n",
      "centroid distance sums [[1335.34858913  950.33428567]]\n",
      "num points in clusters [[6136. 3864.]]\n",
      "centroid distance sums [[1350.87083154  934.51895957]]\n",
      "num points in clusters [[6209. 3791.]]\n",
      "centroid distance sums [[1343.50559215  948.06154946]]\n",
      "num points in clusters [[6165. 3835.]]\n",
      "centroid distance sums [[1363.33236798  931.53707219]]\n",
      "num points in clusters [[6250. 3750.]]\n",
      "centroid distance sums [[1238.92351003 1094.9536125 ]]\n",
      "num points in clusters [[5581. 4419.]]\n",
      "centroid distance sums [[1169.80869111 1224.4537912 ]]\n",
      "num points in clusters [[5080. 4920.]]\n",
      "centroid distance sums [[1165.45814276 1216.8862051 ]]\n",
      "num points in clusters [[5061. 4939.]]\n",
      "centroid distance sums [[1161.98083063 1219.31578023]]\n",
      "num points in clusters [[5093. 4907.]]\n",
      "centroid distance sums [[1158.26338419 1230.94391135]]\n",
      "num points in clusters [[5050. 4950.]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_5.arff'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m sea_stats \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sea_path \u001b[38;5;129;01min\u001b[39;00m all_sea_data_paths:\n\u001b[0;32m      7\u001b[0m     runs_results_bool, final_fpr_mean, fpr_std_err, final_latency_mean, latency_std_err \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m      8\u001b[0m         mssw_eval\u001b[38;5;241m.\u001b[39mall_drifting_batches_randomness_robust(\n\u001b[1;32m----> 9\u001b[0m         \u001b[43msea_reference_batches\u001b[49m\u001b[43m[\u001b[49m\u001b[43msea_path\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[0;32m     10\u001b[0m         sea_testing_batches[sea_path],\n\u001b[0;32m     11\u001b[0m         n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     12\u001b[0m         n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     13\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m550\u001b[39m,\n\u001b[0;32m     14\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     15\u001b[0m         true_drift_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     16\u001b[0m         min_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     18\u001b[0m     sea_stats[sea_path] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns_results_bool\u001b[39m\u001b[38;5;124m'\u001b[39m: runs_results_bool,\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_fpr_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: final_fpr_mean,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatency_std_err\u001b[39m\u001b[38;5;124m'\u001b[39m: latency_std_err\n\u001b[0;32m     24\u001b[0m     }\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEA STATS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '../Datasets_concept_drift/synthetic_data/gradual_drift/sea_1_gradual_drift_0_noise_balanced_5.arff'"
     ]
    }
   ],
   "source": [
    "import mssw_eval\n",
    "\n",
    "\n",
    "\n",
    "sea_stats = {}\n",
    "for sea_path in all_sea_data_paths:\n",
    "    runs_results_bool, final_fpr_mean, fpr_std_err, final_latency_mean, latency_std_err = \\\n",
    "        mssw_eval.all_drifting_batches_randomness_robust(\n",
    "        sea_reference_batches[sea_path],\n",
    "        sea_testing_batches[sea_path],\n",
    "        n_clusters=2,\n",
    "        n_init=100,\n",
    "        max_iter=550,\n",
    "        tol=0,\n",
    "        true_drift_idx=2,\n",
    "        min_runs=2\n",
    "    )\n",
    "    sea_stats[sea_path] = {\n",
    "        'runs_results_bool': runs_results_bool,\n",
    "        'final_fpr_mean': final_fpr_mean,\n",
    "        'fpr_std_err': fpr_std_err,\n",
    "        'final_latency_mean': final_latency_mean,\n",
    "        'latency_std_err': latency_std_err\n",
    "    }\n",
    "\n",
    "print('SEA STATS')\n",
    "print(sea_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "\n",
    "\n",
    "final_result_dict = {\n",
    "    'type_of_data': [], 'dataset': [], 'drift': [], 'width': [], 'encoding': [],\n",
    "    'n_init': [], 'max_iter': [], 'tol': [],\n",
    "    'FPR_mean': [], 'latency_mean': []\n",
    "}\n",
    "\n",
    "for data_path, stats_dict in sea_stats.items():\n",
    "#     data_filename = data_path.split('/')[-1]\n",
    "#     type_of_data = data_path.split('/')[2].split('_')[0]  # synthetic or real-world\n",
    "#     dataset_name = data_filename.split('_')[0]  # sea, agraw1, agraw2\n",
    "#     drift_type = data_path.split('/')[3].split('_')[0]\n",
    "#     drift_width = '0' if drift_type == 'abrupt' else data_filename.split('_')[-1].split('.')[0]\n",
    "#     drift_width = 0.5 if drift_width == '05' else float(drift_width)\n",
    "    synthetic_filename_info = helpers.synthetic_data_information(data_path)\n",
    "    encoding = 'exclude'\n",
    "    fpr_mean = float(stats_dict['final_fpr_mean'])\n",
    "    latency_mean = float(stats_dict['final_latency_mean'])\n",
    "    \n",
    "    final_result_dict['type_of_data'].append(synthetic_filename_info['type_of_data'])\n",
    "    final_result_dict['dataset'].append(synthetic_filename_info['dataset_name'])\n",
    "    final_result_dict['drift'].append(synthetic_filename_info['drift_type'])\n",
    "    final_result_dict['width'].append(synthetic_filename_info['drift_width'])\n",
    "    final_result_dict['encoding'].append(encoding)\n",
    "    final_result_dict['n_init'].append(100)\n",
    "    final_result_dict['max_iter'].append(550)\n",
    "    final_result_dict['tol'].append(0)\n",
    "    final_result_dict['FPR_mean'].append(fpr_mean)\n",
    "    final_result_dict['latency_mean'].append(latency_mean)\n",
    "    \n",
    "final_result_df = pd.DataFrame.from_dict(final_result_dict)\n",
    "sorted_final_result_df = final_result_df.sort_values(['drift', 'dataset', 'encoding', 'width'])\n",
    "final_result_df.to_csv('sea_jupyter_results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
